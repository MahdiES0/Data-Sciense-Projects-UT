{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-weight: bold;\">Data Sciense Course - Spring 1403</h1>\n",
    "<h1 style=\"text-align: center; font-weight: bold;\">Project Phase1 - Introduction to Data Science </h1>\n",
    "<h1 style=\"text-align: center;\">Mohammadreza Mohammadhashemi : 810100206</h1>\n",
    "<h1 style=\"text-align: center;\">Soheil Hajian Manesh : 810100119</h1>\n",
    "<h1 style=\"text-align: center;\">Mahdi Ebrahimi Soltani : 810100241</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "in this phase we are going to scrapping datas from fiverr.com website using BeautifulSoup and selenium packages and then extract some meaningful statistics from dataset using EDA and visualisation and preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "from fiverr_api import session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver(proxy=None):\n",
    "    options = Options()\n",
    "    options.add_argument(r\"user-data-dir=C:\\Users\\Lenovo\\AppData\\Local\\Google\\Chrome\\User Data\")\n",
    "    options.add_argument(r\"profile-directory=Profile 1\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\"\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "base_url = \"https://www.fiverr.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_or_default(element, default=\"N/A\"):\n",
    "    return element.text.strip() if element else default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_price_info(table):\n",
    "    prices = table.find_all(\"div\", class_=\"price-wrapper\")\n",
    "    if len(prices) == 0:\n",
    "        return (\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "        )\n",
    "    return (\n",
    "        get_text_or_default(prices[0]),\n",
    "        get_text_or_default(prices[1]),\n",
    "        get_text_or_default(prices[2]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_price_info_single_plan(soup):\n",
    "    price = soup.find(\"div\", class_=\"price-wrapper\")\n",
    "    if price is None:\n",
    "        return(\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "        )\n",
    "    return (\n",
    "        get_text_or_default(price),\n",
    "        get_text_or_default(price),\n",
    "        get_text_or_default(price)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_delivery_info(table):\n",
    "    row = table.find(\"tr\", class_=\"delivery-time\")\n",
    "    if row is None:\n",
    "        return(\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "        )\n",
    "    tds = row.find_all(\"td\")\n",
    "    delivery_0 = tds[1].find_all(\"label\")[0] if len(tds[1].find_all(\"label\"))>0 else tds[1]\n",
    "    delivery_1 = tds[2].find_all(\"label\")[0] if len(tds[2].find_all(\"label\"))>0 else tds[2]\n",
    "    delivery_2 = tds[3].find_all(\"label\")[0] if len(tds[3].find_all(\"label\"))>0 else tds[3]\n",
    "    return (\n",
    "            get_text_or_default(delivery_0),\n",
    "            get_text_or_default(delivery_1),\n",
    "            get_text_or_default(delivery_2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_delivery_info_single_plan(soup):\n",
    "    delivery = soup.find_all(\"div\", class_=\"delivery-wrapper\")[0]\n",
    "    if delivery is None: \n",
    "        return (\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "        )\n",
    "    return (\n",
    "        get_text_or_default(delivery),\n",
    "        get_text_or_default(delivery),\n",
    "        get_text_or_default(delivery),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_revision_info(table):\n",
    "    rows = table.find_all(\"tr\")\n",
    "    revision_row = None\n",
    "    for row in rows[1:]:\n",
    "        if row.find_all(\"td\")[0].text.strip() == \"Revisions\":\n",
    "            revision_row = row\n",
    "            break\n",
    "    if  revision_row is None:\n",
    "        return (\n",
    "            \"-1\",\n",
    "            \"-1\",\n",
    "            \"-1\",\n",
    "        )\n",
    "\n",
    "    revisions = revision_row.find_all(\"td\") \n",
    "    return (\n",
    "        get_text_or_default(revisions[1]),\n",
    "        get_text_or_default(revisions[2]),\n",
    "        get_text_or_default(revisions[3]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_revision_info_single_plan(soup):\n",
    "    revision_all = soup.find_all(\"div\", class_=\"revisions-wrapper\")\n",
    "    if len(revision_all) == 0:   \n",
    "        return (\n",
    "            \"-1\",\n",
    "            \"-1\",\n",
    "            \"-1\",\n",
    "        )\n",
    "    revision = revision_all[0]\n",
    "    return(\n",
    "        get_text_or_default(revision),\n",
    "        get_text_or_default(revision),\n",
    "        get_text_or_default(revision),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_stats(soup):\n",
    "    seller_card=soup.find(\"div\",class_=\"seller-card\")\n",
    "    user_stats = seller_card.find(\"ul\", class_=\"user-stats\")\n",
    "    country = \"N/A\"\n",
    "    member_since = \"N/A\"\n",
    "    avg_response_time = \"N/A\"\n",
    "    last_delivery = \"N/A\"\n",
    "    language = \"N/A\"\n",
    "    if user_stats:\n",
    "        items=user_stats.find_all(\"li\")\n",
    "        for item in items:\n",
    "            if \"From\" in item.text.strip():\n",
    "                country = get_text_or_default(item.find(\"strong\"))\n",
    "            elif \"Member since\" in item.text.strip():\n",
    "                member_since = get_text_or_default(item.find(\"strong\"))\n",
    "            elif \"Avg. response time\" in item.text.strip():\n",
    "                avg_response_time = get_text_or_default(item.find(\"strong\"))\n",
    "            elif \"Last delivery\" in item.text.strip():\n",
    "                last_delivery = get_text_or_default(item.find(\"strong\"))\n",
    "            elif \"Languages\" in item.text.strip():\n",
    "                language = get_text_or_default(item.find(\"strong\"))\n",
    "\n",
    "        return (\n",
    "            country,\n",
    "            member_since,\n",
    "            avg_response_time,\n",
    "            last_delivery,\n",
    "            language,\n",
    "        )\n",
    "    else : \n",
    "        country = seller_card.find_all(\"p\",class_=\"jpwn1n20u jpwn1n151 jpwn1n138 jpwn1n6 jpwn1n2\")[0]\n",
    "        language = seller_card.find_all(\"span\",class_=\"jpwn1n20u jpwn1n151 jpwn1n138 jpwn1n6 jpwn1n2\")[0]\n",
    "        return(\n",
    "            get_text_or_default(country),\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "            \"N/A\",\n",
    "            get_text_or_default(language),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating_info(soup):\n",
    "    rating = get_text_or_default(soup.find(\"b\", class_=\"rating-score\"))\n",
    "    rating_count = get_text_or_default(soup.find(\"span\", class_=\"rating-count-number\"))\n",
    "    return rating, rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_order_in_queue(soup):\n",
    "    order_in_queue = soup.find(\"div\", class_=\"FVVUrQM\")\n",
    "    return get_text_or_default(order_in_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_records(driver, url, category, field, level, sellers_in_same_level):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        body = driver.find_element(By.CLASS_NAME, \"layout-service\")\n",
    "\n",
    "        html_content = body.get_attribute(\"innerHTML\")\n",
    "\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        table = soup.find(\"div\", class_=\"gig-page-packages-table\")\n",
    "\n",
    "        if table:\n",
    "            is_single_plan = False\n",
    "            basic_price, standard_price, premium_price = extract_price_info(table)\n",
    "            basic_delivery, standard_delivery, premium_delivery = extract_delivery_info(table)\n",
    "            basic_revision, standard_revision, premium_revision = extract_revision_info(table)\n",
    "        else:\n",
    "            is_single_plan = True\n",
    "            basic_price, standard_price, premium_price = extract_price_info_single_plan(soup)\n",
    "            basic_delivery, standard_delivery, premium_delivery = extract_delivery_info_single_plan(soup)\n",
    "            basic_revision, standard_revision, premium_revision = extract_revision_info_single_plan(soup)\n",
    "        rating, rating_count = extract_rating_info(soup)\n",
    "            \n",
    "        country, member_since, avg_response_time, last_delivery, language = extract_user_stats(soup)\n",
    "\n",
    "        order_in_queue = extract_order_in_queue(soup)\n",
    "\n",
    "        return (\n",
    "                category, field, level, sellers_in_same_level,\n",
    "                basic_price, standard_price, premium_price,\n",
    "                basic_delivery, standard_delivery, premium_delivery,\n",
    "                basic_revision, standard_revision, premium_revision,\n",
    "                rating, rating_count, country, member_since,\n",
    "                avg_response_time, last_delivery, language, order_in_queue,\n",
    "                is_single_plan\n",
    "            )\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"Category\",\n",
    "    \"Field\",\n",
    "    \"Seller Level\",\n",
    "    \"Seller In Same Level\",\n",
    "    \"Basic Price\",\n",
    "    \"Standard Price\",\n",
    "    \"Premium Price\",\n",
    "    \"Basic Delivery\",\n",
    "    \"Standard Delivery\",\n",
    "    \"Premium Delivery\",\n",
    "    \"Basic Revision\",\n",
    "    \"Standard Revision\",\n",
    "    \"Premium Revision\",\n",
    "    \"Rating\",\n",
    "    \"Rating Count\",\n",
    "    \"Country\",\n",
    "    \"Member Since\",\n",
    "    \"Avg Response Time\",\n",
    "    \"Last Delivery\",\n",
    "    \"Language\",\n",
    "    \"Order in Queue\",\n",
    "    \"is_single_plan\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_html_files(base_path):\n",
    "    error_links = []\n",
    "    driver = initialize_driver()\n",
    "    for category in os.listdir(base_path):\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for field in os.listdir(category_path):\n",
    "                field_path = os.path.join(category_path, field)\n",
    "                if os.path.isdir(field_path):\n",
    "                    for level in os.listdir(field_path):\n",
    "                        records = []\n",
    "                        level_path = os.path.join(field_path, level)\n",
    "                        sellers_in_same_level = int(level.split(\"_\")[-1])\n",
    "                        for item in os.listdir(level_path):\n",
    "                            item_path = os.path.join(level_path, item)\n",
    "                            if os.path.isfile(item_path):\n",
    "                                seller_level = level.split(\"_\")[0]\n",
    "                                print(item_path)\n",
    "                                item_url = os.path.abspath(item_path)\n",
    "                                record = extract_records(driver,item_url,category,field,seller_level,sellers_in_same_level,)\n",
    "                                if record:\n",
    "                                    records.append(record)\n",
    "                                else:\n",
    "                                    print(\"null return\")\n",
    "                                    error_links.append(item_path)\n",
    "                        field_folder = os.path.join(\"CSVs\", category, field)\n",
    "                        os.makedirs(field_folder, exist_ok=True)\n",
    "                        csv_file_path = os.path.join(\n",
    "                            field_folder, f\"{seller_level}.csv\"\n",
    "                        )\n",
    "                        field_df = pd.DataFrame(records, columns=columns)\n",
    "                        field_df.to_csv(csv_file_path, index=False)\n",
    "    driver.quit()\n",
    "    return error_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_process_html_files(base_path):\n",
    "    error_links = []\n",
    "    driver = initialize_driver()\n",
    "    session.set_scraper_api_key(\"046f60c9745770c0c800a295b5a3e56e\")\n",
    "    temp_file_path = 'temp.html'\n",
    "    for category in os.listdir(base_path):\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for field in os.listdir(category_path):\n",
    "                field_path = os.path.join(category_path, field)\n",
    "                if os.path.isdir(field_path):\n",
    "                    for file_name in [\"0.html\",\"1.html\",\"2.html\", \"3.html\"]:\n",
    "                        file_path = os.path.join(field_path, file_name)\n",
    "                        if os.path.isfile(file_path):\n",
    "                            records = []\n",
    "                            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                                html_content = file.read()\n",
    "                            soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "                            item_divs = soup.find_all(\"div\", class_=\"gig-card-layout\")\n",
    "                            sellers_in_same_level = get_text_or_default(soup.find(\"p\", class_=\"number-of-results\"))\n",
    "                            item_links = []\n",
    "                            for div in item_divs:\n",
    "                                link = div.find_all(\"a\", href=True)[2]\n",
    "                                if link:\n",
    "                                    item_links.append(\"https://www.fiverr.com\" + link[\"href\"])\n",
    "                            seller_level = [\"new seller\",\"level 1\",\"level 2\",\"top rated seller\"][int(file_name[0])]\n",
    "                            for link in item_links:\n",
    "                                print(link)\n",
    "                                response = session.get(link)\n",
    "                                with open(temp_file_path, 'w', encoding='utf-8') as temp_file:\n",
    "                                    temp_file.write(str(response.soup))\n",
    "                                page_url = os.path.abspath(temp_file_path)\n",
    "                                record = extract_records(driver, page_url, category, field, seller_level, sellers_in_same_level)\n",
    "                                if record:\n",
    "                                    records.append(record)\n",
    "                                else:\n",
    "                                    print(\"null return\")\n",
    "                                    error_links.append(link)\n",
    "\n",
    "                            field_folder = os.path.join(\"CSVs\", category, field)\n",
    "                            os.makedirs(field_folder, exist_ok=True)\n",
    "                            csv_file_path = os.path.join(field_folder, f\"{seller_level}.csv\")\n",
    "                            field_df = pd.DataFrame(records, columns=columns)\n",
    "                            field_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    driver.quit()\n",
    "    return error_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"htmls\"\n",
    "errors = create_and_process_html_files(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"items_htmls\"\n",
    "errors = process_html_files(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6262, 22)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "\n",
    "for category in os.listdir(\"CSVs\"):\n",
    "    category_path = os.path.join(\"CSVs\", category)\n",
    "    for field in os.listdir(category_path):\n",
    "        field_path = os.path.join(category_path, field)\n",
    "        if os.path.isdir(field_path):\n",
    "            for csv_file in os.listdir(field_path):\n",
    "                csv_path = os.path.join(field_path, csv_file)\n",
    "                df = pd.read_csv(csv_path)\n",
    "                df_list.append(df)\n",
    "df=pd.read_csv(\"Business.csv\")\n",
    "df_list.append(df)\n",
    "\n",
    "fiverr_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(fiverr_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiverr_df.to_csv(\"Fiverr Dataset\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

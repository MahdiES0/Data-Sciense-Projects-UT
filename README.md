# Data Sciense Course

- [Computer Assignments:](#cas)

  - [_CA0. Web Scraping and Introductory Data Analysis_](#ca0)
  - [_CA1. Statistical Analysis Tools and Techniques_](#ca1)
  - [_CA2. Exploratory Data Analysis and Data Cleaning_](#ca2)
  - [_CA3. Data Processing with PySpark_](#ca3)
  - [_CA4. Regression Analysis and Optimization Techniques_](#ca4)
  - [_CA5. Feature Engineering, Regression, and Cross-Validation_](#ca5)
  - [_CA6. Dimensionality Reduction and Unsupervised Learning_](#ca6)
  - [_CA7. IMDb Review Sentiment Analysis_](#ca7)

- [Project:](#project)
  - [_Phase0. Selecting a Dataset for Data Science Project_](#p0)
  - [_Phase1. Data Scraping , EDA and Visualization_](#p1)
  - [_Phase2. Model Training and Evaluation_](#p2)

## Computer Assignements <a name="cas"></a>

### CA0: Web Scraping and Introductory Data Analysis <a name="ca0"></a>

Learn web scraping to extract Ethereum transaction data from Etherscan.io and conduct basic statistical analysis and visualization. Set up the environment, scrape transaction data, clean and analyze the data, and compare sample statistics with population statistics using various sampling methods. This assignment provides hands-on experience with data collection, cleaning, statistical analysis, and visualization techniques.

### CA1: Statistical Analysis Tools and Techniques <a name="ca1"></a>

This assignment focuses on implementing and understanding various statistical analysis tools, which are essential for future research and projects.Explore Monte Carlo Simulation, the Central Limit Theorem, and Hypothesis Testing, using libraries such as NumPy, Matplotlib, and SciPy.

### CA2: Exploratory Data Analysis and Data Cleaning<a name="ca2"></a>

This assignment focuses on investigating open-ended questions through creative and critical analysis of data. You will work with datasets to gain insights using tools such as NumPy, pandas, and Matplotlib.
**Datasets:**

- task1.csv: Contains information about the passengers of the sunken ship 'RMS Lusitania'.
- task2.csv: Contains information about data scientist salaries across different regions from 2020 to 2024.

### CA3: Data Processing with PySpark<a name="ca3"></a>

This assignment involves working with PySpark, the Python API for Apache Spark, to perform real-time, large-scale data processing in a distributed environment using Python.

**Datasets:**

- stocks.csv: Contains information about stock market prices and volumes.
- spotify.parquet: Contains information about songs streamed on Spotify, including details about the album, artist, musical characteristics, and release date.

### CA4: Regression Analysis and Optimization Techniques<a name="ca4"></a>

This assignment focuses on exploring various loss functions and applying gradient descent methods to optimize these functions using the Diabetes dataset from the scikit-learn library. The dataset consists of medical diagnostic measurements designed to study diabetes progression. You will predict the quantitative measure of disease progression one year after baseline, practicing regression analysis in a medical context

### CA5: Feature Engineering, Regression, and Cross-Validation<a name="ca5"></a>

This assignment focuses on applying feature engineering techniques to a football-related dataset and implementing multivariate regression and k-fold cross-validation from scratch. The goal is to analyze the likelihood of scoring a goal through a shot in football and predict car prices and horsepower using regression models.

**Datasets:**

- football.csv: Contains information about football shots, including timing, location, and outcome.
- cars.csv: Contains preprocessed information about cars, including features like price and horsepower.

### CA6: Dimensionality Reduction and Unsupervised Learning<a name="ca6"></a>

This assignment focuses on dimensionality reduction and unsupervised learning tasks using a dataset of diabetic patient records. The goal is to preprocess the dataset, apply dimensionality reduction techniques, and utilize unsupervised learning algorithms for clustering analysis.

**Dataset:** The dataset contains data on diabetic patients from various hospitals and clinics in America, comprising 200,000 items with 50 features.

### CA7: IMDb Review Sentiment Analysis<a name="ca7"></a>

This assignment focuses on training a model to classify IMDb review comments automatically. The tasks involve exploring the dataset, performing feature engineering, and implementing semi-supervised learning techniques.

**Dataset:** The dataset comprises movie reviews submitted by users on IMDb for sentiment analysis tasks. Each entry in the dataset includes the text of a review, its corresponding sentiment label (1 for positive, 0 for negative), and a feature vector (embedding) for each comment.

## Project <a name="project"></a>

### Phase0: Selecting a Dataset for Data Science Project <a name="p0"></a>

In this phase we just choose Fiverr.com to mining data from it. **Fiverr.com** is an online marketplace that connects freelancers with clients who need various services.

### Phase1: Data Scraping , EDA and Visualization <a name="p1"></a>

In Phase 1 of our project,first we collect our dataset from `Fiverr.com`.our dataset contains about 6200 record from freelancers services.Then we conduct Exploratory Data Analysis (EDA) and visualization to gain insights into our dataset. By analyzing the variables and their relationships, we aim to understand the underlying patterns, trends, and characteristics of the data. This phase will provide a solid foundation for further analysis and modeling in subsequent phases.

### Phase2: Model Training and Evaluation <a name="p2"></a>

In this phase of the project, our main objective is to train machine learning models to predict the target variable using the dataset analyzed in previous phases. We will follow a structured approach consisting of several parts:

1. Preprocessing
2. Feature Engineering and Selection
3. Dimensionality Reduction
4. Evaluation Metric
5. Model Training
6. Feature Analysis
7. Overall Report and Discussions
